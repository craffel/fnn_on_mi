{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import sys\n",
      "import os\n",
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "import lasagne\n",
      "\n",
      "import random\n",
      "import h5py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readHTKfeat(dataPath):\n",
      "    data = np.array([[]])\n",
      "    flagDataStart = 0\n",
      "    nLine = 0\n",
      "    i = -1\n",
      "    for line in open(dataPath,'r'):\n",
      "        if line.find('END') != -1:\n",
      "            return data\n",
      "        if flagDataStart:\n",
      "            if nLine == 0:\n",
      "                dataLine = np.array([float(x) for x in line.split()[1:]])\n",
      "                nLine = nLine + 1\n",
      "                i = i+1\n",
      "                continue\n",
      "            elif nLine in [1,2]:\n",
      "                dataLine = np.concatenate((dataLine,[float(x) for x in line.split()]))    \n",
      "                nLine = nLine + 1\n",
      "                continue\n",
      "            elif nLine == 3:\n",
      "                dataLine = np.concatenate((dataLine,[float(x) for x in line.split()]))\n",
      "                data[i,:] = dataLine\n",
      "                nLine = 0\n",
      "                continue\n",
      "                \n",
      "        if line.find('------------------------------------ Samples: 0->-1 ------------------------------------') != -1:\n",
      "            flagDataStart = 1\n",
      "   \n",
      "        if line.find('Num Samples') != -1:\n",
      "            nSamples = int(line.split()[2])\n",
      "            data = np.ndarray(shape=(nSamples,N_FEATURE_DIM))\n",
      "            flagDataStart= 0\n",
      "\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Setting\n",
      "\n",
      "# Number of units in the hidden (recurrent) layer\n",
      "N_HIDDEN = 10\n",
      "# Number of training sequences in each batch\n",
      "N_BATCH = 10\n",
      "# Optimization learning rate\n",
      "LEARNING_RATE = .001\n",
      "# All gradients above this will be clipped\n",
      "GRAD_CLIP = 100\n",
      "# How often should we check the output?\n",
      "EPOCH_SIZE = 1\n",
      "# Number of epochs to train the net\n",
      "NUM_EPOCHS = 100\n",
      "# Number of feature dimentions\n",
      "N_FEATURE_DIM = 39"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h5File = 'mfcc.h5'\n",
      "if os.path.exists(h5File):\n",
      "    print('loading from h5 file...')\n",
      "    sys.stdout.write(\"\\033[F\")\n",
      "    f = h5py.File(h5File,'r')\n",
      "    X = f['X'][:]\n",
      "    Y = f['Y'][:]\n",
      "    mask = f['mask'][:]\n",
      "    N_SEQ = len(Y)\n",
      "    MAX_LENGTH=15000\n",
      "    f.close()\n",
      "    print('DONE')\n",
      "else:\n",
      "    ## Load Feature\n",
      "    dataDir = '/home/james/data/MFCC/MFCC_E_D_A_txt/'\n",
      "    featDic = {}\n",
      "    dirList=os.listdir(dataDir)\n",
      "    for i in range(len(dirList)):\n",
      "        if i%100 == 0:\n",
      "            print('reading %d,'%i)\n",
      "        dataPath = os.path.join(dataDir,dirList[i])\n",
      "        try:\n",
      "            data = readHTKfeat(dataPath)\n",
      "            featDic.update({dirList[i]:data})\n",
      "        except:\n",
      "            print(dataPath)\n",
      "    print('Loading DONE')\n",
      "    ## Read label\n",
      "    lab = ['angry','sad','inneed','happy','alert','scary','nobark']\n",
      "    labDic = {}\n",
      "    for k in featDic:\n",
      "        for i,l in enumerate(lab):\n",
      "            if k.find(l) != -1:\n",
      "                labDic[k] = i\n",
      "                continue\n",
      "    ## Format Data\n",
      "    # Number of sequences\n",
      "    N_SEQ = len(labDic)\n",
      "    # Max sequence length\n",
      "    MAX_LENGTH = 15000\n",
      "    ## Format data into X Y and mask \n",
      "    X = np.zeros(shape=(N_SEQ, MAX_LENGTH, N_FEATURE_DIM))\n",
      "    mask = np.zeros((N_SEQ, MAX_LENGTH))\n",
      "    Y = np.zeros((N_SEQ,))\n",
      "    for i,k in enumerate(labDic):\n",
      "        X[i,0:len(featDic[k]),:] = featDic[k]\n",
      "        mask[i] = [1]*len(featDic[k])+[0]*(MAX_LENGTH-len(featDic[k]))\n",
      "        Y[i] = labDic[k]\n",
      "    Y = Y.astype('int32')\n",
      "    del featDic\n",
      "    del labDic\n",
      "    print('Formating data DONE')\n",
      "    ## Save Data\n",
      "    f = h5py.File('mfcc.h5','w')\n",
      "    f.create_dataset('X',data=X)\n",
      "    f.create_dataset('Y',data=Y)\n",
      "    f.create_dataset('mask',data=mask)\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading 0,\n",
        "reading 100,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/james/data/MFCC/MFCC_E_D_A_txt/poodle_male_0.6_stand_inneed_20150827_205512.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 200,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 300,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 400,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 500,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 600,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 700,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 800,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 900,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 1000,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loading DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Formating data DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Load Feature\n",
      "dataDir = '/home/james/data/MFCC/MFCC_E_D_A_txt/'\n",
      "saveDir = '/home/james/data/MFCC/MFCC_E_D_A_h5/'\n",
      "featDic = {}\n",
      "dirList=os.listdir(dataDir)\n",
      "for i in range(len(dirList)):\n",
      "    if i%100 == 0:\n",
      "        print('reading %d,'%i)\n",
      "    dataPath = os.path.join(dataDir,dirList[i])\n",
      "    try:\n",
      "        data = readHTKfeat(dataPath)\n",
      "        featDic.update({dirList[i]:data})\n",
      "    except:\n",
      "        print(dataPath)\n",
      "        continue\n",
      "    ## Read label\n",
      "    lab = ['angry','sad','inneed','happy','alert','scary','nobark']\n",
      "    for ind,l in enumerate(lab):\n",
      "        if dirList[ind].find(l) != -1:\n",
      "            Y = ind\n",
      "            continue\n",
      "    ## Format Data\n",
      "    # Max sequence length\n",
      "    MAX_LENGTH = 15000\n",
      "    ## Format data into X Y and mask \n",
      "    X = np.zeros(shape=(1, MAX_LENGTH, N_FEATURE_DIM))\n",
      "    mask = np.zeros((1, MAX_LENGTH))\n",
      "    Y = np.zeros((1,))\n",
      "    X[0,0:len(data),:] = data\n",
      "    mask[0] = [1]*len(data)+[0]*(MAX_LENGTH-len(data))\n",
      "    Y = Y.astype('int32')\n",
      "    ## Save Data\n",
      "    f = h5py.File(os.path.join(saveDir,os.path.splitext(dirList[i])[0]+'.h5'),'w')\n",
      "    f.create_dataset('data',data=X)\n",
      "    f.create_dataset('label',data=Y)\n",
      "    f.create_dataset('mask',data=mask)\n",
      "    f.close()\n",
      "#    print('Formating data DONE')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "reading 0,\n",
        "reading 100,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/james/data/MFCC/MFCC_E_D_A_txt/poodle_male_0.6_stand_inneed_20150827_205512.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 200,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 300,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 400,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 500,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 600,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 700,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 800,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 900,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading 1000,"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class data_generator():\n",
      "    def __init__(self,x,y,m,n_batch=N_BATCH,isShuffle = True):\n",
      "        import random\n",
      "        # data\n",
      "        self.x=x\n",
      "        self.y=y\n",
      "        self.m=m\n",
      "        self.n_batch = n_batch\n",
      "        # index\n",
      "        self.index = range(len(y))\n",
      "        if isShuffle:\n",
      "            random.shuffle(self.index)\n",
      "        self.used_index = []\n",
      "    def get_batch(self):\n",
      "        self.used_index = self.used_index + self.index[:self.n_batch]\n",
      "        minibatch = (self.x[self.index[:self.n_batch]],self.y[self.index[:self.n_batch]],self.m[self.index[:self.n_batch]])\n",
      "        self.index = self.index[self.n_batch:]\n",
      "        return minibatch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class data_generator_from_h5():\n",
      "    # use this function to read minibatch from hard disk, in order to reduce memory usage\n",
      "    def __init__(self,file_list,n_batch=N_BATCH,isShuffle = True):\n",
      "        import random\n",
      "        # data\n",
      "        self.list = file_list\n",
      "        self.n_batch = n_batch\n",
      "        # index\n",
      "        self.index = range(len(file_list))\n",
      "        if isShuffle:\n",
      "            random.shuffle(self.index)\n",
      "        self.used_index = []\n",
      "        \n",
      "    def get_batch(self):\n",
      "        self.used_index = self.used_index + self.index[:self.n_batch]            \n",
      "        minibatch = read_from_list(self.list[self.index[:self.n_batch]])\n",
      "        self.index = self.index[self.n_batch:]\n",
      "        return minibatch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_from_list(f_list):\n",
      "    for iFile in f_list:\n",
      "        f = h5py.File(iFile.strip())\n",
      "        if 'X' not in locals():\n",
      "            X = f['data'][:]\n",
      "            Y = f['label'][:]\n",
      "            mask = f['mask'][:]\n",
      "        else:\n",
      "            X = np.concatenate((X,f['data'][:]),axis=0)\n",
      "            Y = np.concatenate((Y,f['label'][:]),axis=0)\n",
      "            mask = np.concatenate((mask,f['mask'][:]),axis=0)\n",
      "        f.close()\n",
      "    return (X,Y,mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# shuffle dataset\n",
      "dataList = np.array([os.path.join(saveDir,ifile) for ifile in os.listdir(saveDir)])\n",
      "N_SEQ = len(dataList)\n",
      "index = range(N_SEQ)\n",
      "random.shuffle(range(N_SEQ))\n",
      "\n",
      "## split into train val test\n",
      "trainPortion,valPortion = [int(i*N_SEQ) for i in [0.7,0.8]]\n",
      "\n",
      "list_train = dataList[index[:trainPortion]]\n",
      "\n",
      "list_val = dataList[index[trainPortion:valPortion]]\n",
      "X_val,Y_val,mask_val = read_from_list(list_val)\n",
      "list_test = dataList[index[valPortion:]]\n",
      "X_test,Y_test,mask_test = read_from_list(list_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Building network ...\")\n",
      "N_LSTM = 128\n",
      "N_DENSE = 50\n",
      "# First, we build the network, starting with an input layer\n",
      "# Recurrent layers expect input of shape\n",
      "# (batch size, max sequence length, number of features)\n",
      "l_in = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH, N_FEATURE_DIM))\n",
      "# The network also needs a way to provide a mask for each sequence.  We'll\n",
      "# use a separate input layer for that.  Since the mask only determines\n",
      "# which indices are part of the sequence for each batch entry, they are\n",
      "# supplied as matrices of dimensionality (N_BATCH, MAX_LENGTH)\n",
      "l_mask = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH))\n",
      "# Setting a value for grad_clipping will clip the gradients in the layer\n",
      "# Setting only_return_final=True makes the layers only return their output\n",
      "# for the final time step, which is all we need for this task\n",
      "\n",
      "#l_forward1 = lasagne.layers.LSTMLayer(l_in, N_LSTM, mask_input=l_mask,only_return_final=False)\n",
      "#l_forward2 = lasagne.layers.LSTMLayer(l_forward1, N_LSTM, mask_input=l_mask,only_return_final=False)\n",
      "#l_forward3 = lasagne.layers.LSTMLayer(l_forward2, N_LSTM, mask_input=l_mask,only_return_final=False)\n",
      "l_forward = lasagne.layers.LSTMLayer(l_in, N_LSTM, mask_input=l_mask,only_return_final=True)\n",
      "#l_forward = lasagne.layers.RecurrentLayer(\n",
      "#    l_in, N_HIDDEN, mask_input=l_mask, grad_clipping=GRAD_CLIP,\n",
      "#    W_in_to_hid=lasagne.init.HeUniform(),\n",
      "#    W_hid_to_hid=lasagne.init.HeUniform(),\n",
      "#    nonlinearity=lasagne.nonlinearities.tanh, only_return_final=True)\n",
      "\n",
      "#    l_backward = lasagne.layers.RecurrentLayer(\n",
      "#        l_in, N_HIDDEN, mask_input=l_mask, grad_clipping=GRAD_CLIP,\n",
      "#        W_in_to_hid=lasagne.init.HeUniform(),\n",
      "#        W_hid_to_hid=lasagne.init.HeUniform(),\n",
      "#        nonlinearity=lasagne.nonlinearities.tanh,\n",
      "#        only_return_final=True, backwards=True)\n",
      "#    # Now, we'll concatenate the outputs to combine them.\n",
      "#    l_concat = lasagne.layers.ConcatLayer([l_forward, l_backward])\n",
      "# Our output layer is a simple dense connection, with 1 output unit\n",
      "#l_dropout = lasagne.layers.dropout(l_forward)\n",
      "l_dense = lasagne.layers.DenseLayer(l_forward,num_units=N_DENSE)\n",
      "\n",
      "l_out = lasagne.layers.DenseLayer(\n",
      "    l_dense, num_units=6, nonlinearity=lasagne.nonlinearities.softmax)\n",
      "\n",
      "target_values = T.ivector('target_output')\n",
      "\n",
      "# lasagne.layers.get_output produces a variable for the output of the net\n",
      "network_output = lasagne.layers.get_output(l_out)\n",
      "\n",
      "# Our cost will be mean-squared error\n",
      "#cost = T.mean((predicted_values - target_values)**2)\n",
      "cost = lasagne.objectives.categorical_crossentropy(network_output,target_values)\n",
      "cost = cost.mean()\n",
      "# Retrieve all parameters from the network\n",
      "all_params = lasagne.layers.get_all_params(l_out)\n",
      "# Compute SGD updates for training\n",
      "print(\"Computing updates ...\")\n",
      "updates = lasagne.updates.adagrad(cost, all_params, LEARNING_RATE)\n",
      "# Theano functions for training and computing cost\n",
      "print(\"Compiling functions ...\")\n",
      "train = theano.function([l_in.input_var, target_values, l_mask.input_var],\n",
      "                        cost, updates=updates)\n",
      "compute_cost = theano.function(\n",
      "    [l_in.input_var, target_values, l_mask.input_var], cost)\n",
      "get_output = theano.function(\n",
      "    [l_in.input_var, l_mask.input_var], lasagne.layers.get_output(l_out, deterministic=True))\n",
      "print(\"Building network ... DONE\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building network ...\n",
        "Computing updates ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Compiling functions ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Building network ... DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/james/Download/Theano/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
        "  'must be passed as a part of non_sequences', Warning)\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def early_stop(valArray,NOT_BETTER_NUM = 10):\n",
      "    if len(valArray) < NOT_BETTER_NUM:\n",
      "        return False\n",
      "    else:\n",
      "        length = len(valArray)\n",
      "        for i,n in enumerate(valArray[length-NOT_BETTER_NUM:-2]):\n",
      "            if valArray[i]>valArray[i+1]:\n",
      "                return False\n",
      "    return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cost_val = compute_cost(X_val, Y_val, mask_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "print(cost_val)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.83914323905\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We'll use this \"validation set\" to periodically check progress\n",
      "print(\"Training ...\")\n",
      "print(time.strftime('%X %x %Z'))\n",
      "earlyStop=0\n",
      "costTrainArray = []\n",
      "costValArray = []\n",
      "hitTestArray = []\n",
      "\n",
      "try:\n",
      "    for epoch in range(NUM_EPOCHS):\n",
      "        data = data_generator_from_h5(list_train,isShuffle=True)\n",
      "        \n",
      "        for _ in range(EPOCH_SIZE):\n",
      "            X_batch, Y_batch, m_batch = data.get_batch()\n",
      "#            print(X_batch.shape,Y_batch.shape,m_batch.shape)\n",
      "            train(X_batch, Y_batch, m_batch)\n",
      "\n",
      "        cost_val = compute_cost(X_val, Y_val, mask_val)\n",
      "        cost_train = compute_cost(X_train, Y_train, mask_train)\n",
      "        output = get_output(X_test,mask_test)\n",
      "        val_predictions = np.argmax(output, axis=1)\n",
      "        hit = np.sum(val_predictions == Y_test)\n",
      "        \n",
      "        print(\"Epoch {} train cost = {}\".format(epoch, cost_train))\n",
      "        print(\"Epoch {} validation cost = {}\".format(epoch, cost_val))\n",
      "        print(\"Epoch {} correctly predicted {} out of {}\".format(epoch, hit,len(Y_test)))\n",
      "        print(time.strftime('%X %x %Z'))\n",
      "        costTrainArray.append(cost_train)\n",
      "        costValArray.append(cost_val)\n",
      "        hitTestArray.append(hit)\n",
      "        \n",
      "        earlyStop = early_stop(costValArray)\n",
      "        if earlyStop:\n",
      "            break\n",
      "except KeyboardInterrupt:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'train' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-34-a9296515c3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#            print(X_batch.shape,Y_batch.shape,m_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcost_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training ...\n",
        "17:01:33 01/07/16 CST\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out_train = get_output(X_train,mask_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_predictions = np.argmax(out_train, axis=1)\n",
      "hit = np.sum(train_predictions == Y_train)\n",
      "print (hit,len(Y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "127 714\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(val_predictions)\n",
      "print(Y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[3 3 5 3 2 0 0 5 0 0 3 0 5 3 0 5 0 0 5 3 0 0 5 3 1 5 5 3 3 2 3 3 0 5 3 0 1\n",
        " 0 3 0 5 3 3 3 4 3 3 3 3 3 5 0 0 0 3 3 3 3 3 5 0 5 0 3 0 3 1 3 3 4 0 5 0 0\n",
        " 1 1 3 4 5 0 0 3 0 5 3 5 4 2 0 0 3 0 2 3 5 3 3 5 0 3 3 3 1 5 5 5 3 3 3 1 5\n",
        " 3 3 0 3 5 3 0 0 3 0 0 5 5 3 5 3 3 2 0 3 5 4 5 3 3 5 0 5 5 3 5 1 0 5 0 3 4\n",
        " 0 2 1 5 3 3 3 1 3 5 3 0 5 0 0 0 5 3 1 5 0 2 3 3 0 3 3 3 3 0 0 5 0 1 5 0 4\n",
        " 5 1 5 0 3 4 0 0 5 0 3 3 3 0 5 2 0 0 3 3]\n",
        "[4 0 3 1 5 2 1 2 2 0 4 0 1 2 0 3 3 4 2 0 3 0 2 2 1 4 0 4 2 0 2 0 1 2 2 4 3\n",
        " 0 2 0 1 1 0 3 5 3 1 4 0 2 3 2 1 2 4 4 2 2 4 2 2 3 4 2 0 2 0 1 4 3 3 1 1 1\n",
        " 1 4 0 0 4 4 2 0 4 2 1 4 0 1 0 4 5 0 1 0 3 4 2 0 2 0 2 1 1 2 0 4 4 3 2 1 0\n",
        " 2 5 1 3 0 5 2 2 4 0 0 0 1 2 2 2 0 4 0 0 0 3 2 0 1 1 3 2 0 4 0 3 4 0 4 2 4\n",
        " 4 5 3 5 5 3 4 3 2 1 2 0 2 3 5 0 4 4 2 3 1 0 4 3 4 1 2 4 4 3 0 0 1 3 3 2 4\n",
        " 1 0 3 3 0 3 3 1 3 5 2 0 2 0 0 5 1 3 4 5]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## build nueral network\n",
      "\n",
      "# input layer: \n",
      "# (batch size, max sequence length, number of features)\n",
      "l_in = lasagne.layers.InputLayer(shape=(NBATCH,MAXLEN,NFEATDIM),\n",
      "                                     input_var=input_var)\n",
      "l_mask = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## save model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}